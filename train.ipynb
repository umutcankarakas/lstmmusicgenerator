{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train_reduced.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1KNAvoQhjYkJGgivSG7UxViJVSihcx9Mh",
      "authorship_tag": "ABX9TyODuykQlIJAep5pBSArfWdy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/umutcankarakas/lstmmusicgenerator/blob/master/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVvFUC7jweP-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3c31911b-4bef-4228-e720-2f0dbf322ebf"
      },
      "source": [
        "!git clone https://github.com/umutcankarakas/theorygenerator.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'theorygenerator'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 51 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (51/51), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0OZBiO-vWX-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "bfe6956f-a329-4f18-b016-9ea7a388e707"
      },
      "source": [
        "!pip install keras-self-attention"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-self-attention\n",
            "  Downloading https://files.pythonhosted.org/packages/15/6b/c804924a056955fa1f3ff767945187103cfc851ba9bd0fc5a6c6bc18e2eb/keras-self-attention-0.46.0.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (1.18.5)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-self-attention) (2.3.1)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.4.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (2.10.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-self-attention) (3.13)\n",
            "Building wheels for collected packages: keras-self-attention\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.46.0-cp36-none-any.whl size=17278 sha256=c34af8d65a0f0ea86204d71c9489b81e65235bcab791cfaecee19623d6327367\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/2e/80/fec4c05eb23c8e13b790e26d207d6e0ffe8013fad8c6bdd4d2\n",
            "Successfully built keras-self-attention\n",
            "Installing collected packages: keras-self-attention\n",
            "Successfully installed keras-self-attention-0.46.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_zvyBGIwwrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b135957e-ac68-46c6-e3a1-6f3fa87de3be"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from pathlib import *\n",
        "import glob\n",
        "import pickle\n",
        "import numpy\n",
        "from music21 import converter, instrument, note, chord, stream\n",
        "from keras.models import Sequential\n",
        "from keras.layers import BatchNormalization as BatchNorm\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation, Bidirectional, Flatten\n",
        "#from keras import utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras_self_attention import SeqSelfAttention\n",
        "from matplotlib import pyplot as plt\n",
        "import string"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFkXiPHmwzlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('theorygenerator')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8mUl6FWw2NA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_path = '../drive/My Drive/full_set_beethoven_mozart/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cd7Q9-H2w5zc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_network():\n",
        "    \"\"\" Train a Neural Network to generate music \"\"\"\n",
        "    notes = get_notes()\n",
        "\n",
        "    # get amount of pitch names\n",
        "    n_vocab = 128 + 128 + 2\n",
        "\n",
        "    network_input, network_output = prepare_sequences(notes, n_vocab)\n",
        "\n",
        "    model = create_network(network_input, n_vocab)\n",
        "    history = train(model, network_input, network_output)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56DmqL0ww69w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convertMidi2Arr(midi_element):\n",
        "  newlist = []\n",
        "  max_duration = 8*4*4\n",
        "  if isinstance(midi_element, note.Note):\n",
        "    newlist.append(midi_element.pitch.midi)\n",
        "    if int(round(midi_element.duration.quarterLength*4)) > max_duration:\n",
        "      newlist.append(128 + max_duration)\n",
        "    else:\n",
        "      newlist.append(128 + int(round(midi_element.duration.quarterLength*4)))\n",
        "  elif isinstance(midi_element, chord.Chord):\n",
        "    for n in midi_element:\n",
        "      newlist.append(n.pitch.midi) \n",
        "      if int(round(midi_element.duration.quarterLength*4)) > max_duration:\n",
        "        newlist.append(128 + max_duration)\n",
        "      else:\n",
        "        newlist.append(128 + int(round(midi_element.duration.quarterLength*4)))\n",
        "  elif isinstance(midi_element, note.Rest):\n",
        "    newlist.append(128)\n",
        "    if int(round(midi_element.duration.quarterLength*4)) > max_duration:\n",
        "      newlist.append(128 + max_duration)\n",
        "    else:\n",
        "      newlist.append(128 + int(round(midi_element.duration.quarterLength*4)))\n",
        "  return newlist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mlMr18Ww9Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_notes():\n",
        "  mylist = []\n",
        "  count = 0\n",
        "  last_offset = 0.0\n",
        "  offset_diff = 0.0\n",
        "  for file in glob.glob(train_path + '**/*.mid', recursive=True):\n",
        "    try:\n",
        "      midi = converter.parse(file)\n",
        "    except:\n",
        "      continue\n",
        "    #print(\"Parsing %s\" % file)\n",
        "    #print(count)\n",
        "    notes_to_parse = None\n",
        "    max_duration = 8*4*4\n",
        "\n",
        "    try: # file has instrument parts\n",
        "      s2 = instrument.partitionByInstrument(midi_piece)\n",
        "      notes_to_parse = s2.parts[0].recurse() \n",
        "    except: # file has notes in a flat structure\n",
        "      notes_to_parse = midi.flat.notesAndRests\n",
        "\n",
        "    same_offset_elements = []\n",
        "    #min_duration = max_duration\n",
        "    for element in notes_to_parse:\n",
        "      if isinstance(element, note.Note) or isinstance(element, chord.Chord) or isinstance(element, note.Rest):\n",
        "        if( not same_offset_elements or same_offset_elements[0].offset == element.offset):\n",
        "          same_offset_elements.append(element)\n",
        "        else:\n",
        "          add_arr = []\n",
        "          #flags = [0,0,0]\n",
        "          for toadd_midi in same_offset_elements:\n",
        "            toadd = convertMidi2Arr(toadd_midi)\n",
        "            if toadd[0]==128:\n",
        "              continue\n",
        "            add_arr.extend(toadd)\n",
        "          if(element.offset > last_offset):\n",
        "            offset_diff = same_offset_elements[0].offset - last_offset\n",
        "            last_offset = same_offset_elements[0].offset\n",
        "          if mylist and mylist[-1] != '_':\n",
        "            mylist.append(257)\n",
        "            mylist.append(128+int(round(offset_diff*4)))\n",
        "            mylist.extend(add_arr)\n",
        "          else:\n",
        "            mylist.extend(add_arr)\n",
        "\n",
        "          offset_diff = 0.0\n",
        "          same_offset_elements = []\n",
        "          same_offset_elements.append(element)\n",
        "\n",
        "    if same_offset_elements:\n",
        "      add_arr = []\n",
        "      for toadd_midi in same_offset_elements:\n",
        "        toadd = convertMidi2Arr(toadd_midi)\n",
        "        if toadd[0]==128:\n",
        "          continue\n",
        "        add_arr.extend(toadd)\n",
        "      if(element.offset > last_offset):\n",
        "        offset_diff = same_offset_elements[0].offset - last_offset\n",
        "        last_offset = same_offset_elements[0].offset\n",
        "      if mylist and mylist[-1] != '_':\n",
        "        mylist.append(257)\n",
        "        mylist.append(128+int(round(offset_diff*4)))\n",
        "        mylist.extend(add_arr)\n",
        "      else:\n",
        "        mylist.extend(add_arr)\n",
        "\n",
        "    if count != 0: count = count + 1\n",
        "    else: break\n",
        "    mylist.append('_')\n",
        "\n",
        "  with open('../drive/My Drive/data/notes_attention_mozbet', 'wb') as filepath:\n",
        "    pickle.dump(mylist, filepath)\n",
        "  return mylist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0anUuRPwxA2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_sequences(notes, n_vocab):\n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    sequence_length = 400\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        if '_' in sequence_in:\n",
        "          i = sequence_in.index('_') + 1\n",
        "          continue\n",
        "        elif sequence_out == '_':\n",
        "          i = i + sequence_length +1\n",
        "          continue\n",
        "        \n",
        "        network_input.append([element for element in sequence_in])\n",
        "        network_output.append(sequence_out)\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    network_input = numpy.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    # normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return (network_input, network_output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPVFuzn-ZW0s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network_1(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    if(os.path.exists('../drive/My Drive/bach_poins/weghts-improvement-292-0.2710-bigger.hdf5')): model.load_weights('../drive/My Drive/bach_points/weights-improvement-292-0.2710-bigger.hdf5')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkNFawPNmxJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network_2(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]), #n_time_steps, n_features?\n",
        "        return_sequences=True)))\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    model.add(LSTM(512,return_sequences=True))\n",
        "    model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    if(os.path.exists('../drive/My Drive/bach_points/weghts-improvement-292-0.2710-bigger.hdf5')): model.load_weights('../drive/My Drive/bach_points/weights-improvement-292-0.2710-bigger.hdf5')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC4D-wmszYmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network_3(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True))\n",
        "    model.add(LSTM(512, return_sequences=True))\n",
        "    model.add(LSTM(512, return_sequences=True))\n",
        "    model.add(LSTM(512, return_sequences=True))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    if(os.path.exists('../drive/My Drive/checkpoints_6lstm_se400only_t/weights-024-0.8723.hdf5')): model.load_weights('../drive/My Drive/checkpoints_6lstm_seq400_only_t/weights-024-0.8723.hdf5')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFHT1UYbvYmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network_4(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        recurrent_dropout=0.2,\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(LSTM(512, return_sequences=True, recurrent_dropout=0.2,))\n",
        "    model.add(LSTM(512))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(256))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNorm())\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    if(os.path.exists('../drive/My Drive/bach_poins/weghts-improvement-292-0.2710-bigger.hdf5')): model.load_weights('../drive/My Drive/bach_points/weights-improvement-292-0.2710-bigger.hdf5')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMXGljnU3Khv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network_5(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]), #n_time_steps, n_features?\n",
        "        return_sequences=True)))\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    model.add(LSTM(512,return_sequences=True))\n",
        "    model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    if(os.path.exists('../drive/My Drive/bach_ponts/weghts-improvement-292-0.2710-bigger.hdf5')): model.load_weights('../drive/My Drive/bach_points/weights-improvement-292-0.2710-bigger.hdf5')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPo6jHSP5z_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]), #n_time_steps, n_features?\n",
        "        return_sequences=True)))\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    #model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(LSTM(512,return_sequences=True))\n",
        "    #model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    if(os.path.exists('../drive/My Drive/checkpoints_attentio/weights-00-0.0274.hdf5')): model.load_weights('../drive/My Drive/checkpoints_attention/weights-200-0.0274.hdf5')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIQhqxV0N1U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_network_7(network_input, n_vocab):\n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    model = Sequential()\n",
        "    model.add(Bidirectional(LSTM(512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]), #n_time_steps, n_features?\n",
        "        return_sequences=True)))\n",
        "    model.add(SeqSelfAttention(attention_activation='sigmoid'))\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(LSTM(512,return_sequences=True))\n",
        "    model.add(Dropout(0.3))\n",
        "    \n",
        "    model.add(Flatten()) #Supposedly needed to fix stuff before dense layer\n",
        "    model.add(Dense(n_vocab))\n",
        "    model.add(Activation('softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
        "    if(os.path.exists('../drive/My Drive/checkpoints_attentio/weights-00-0.0274.hdf5')): model.load_weights('../drive/My Drive/checkpoints_attention/weights-200-0.0274.hdf5')\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct84xlwRs3m4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, network_input, network_output):\n",
        "    \"\"\" train the neural network \"\"\"\n",
        "    filepath = os.path.abspath(\"../drive/My Drive/checkpoints_attention_mozbet/weights-{epoch:03d}-{loss:.4f}.hdf5\")\n",
        "    \n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath,\n",
        "        period=10, #Every epoch\n",
        "        monitor='loss',\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "    )\n",
        "    callbacks_list = [checkpoint]\n",
        "\n",
        "    history = model.fit(network_input, network_output, epochs=200, batch_size=64, callbacks=callbacks_list, validation_split=0.2, shuffle=True)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-_ELR9axKD0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eac3404d-a518-49d7-abda-cc988b986382"
      },
      "source": [
        "history = None\n",
        "if __name__ == '__main__':\n",
        "    history = train_network()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4534 samples, validate on 1134 samples\n",
            "Epoch 1/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 3.9690 - accuracy: 0.2333 - val_loss: 3.1537 - val_accuracy: 0.3095\n",
            "Epoch 2/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 3.2347 - accuracy: 0.2574 - val_loss: 3.0650 - val_accuracy: 0.3095\n",
            "Epoch 3/200\n",
            "4534/4534 [==============================] - 165s 36ms/step - loss: 3.0614 - accuracy: 0.2750 - val_loss: 3.0349 - val_accuracy: 0.1720\n",
            "Epoch 4/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 3.0411 - accuracy: 0.2620 - val_loss: 2.9948 - val_accuracy: 0.3095\n",
            "Epoch 5/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 2.9887 - accuracy: 0.2922 - val_loss: 3.1070 - val_accuracy: 0.1720\n",
            "Epoch 6/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 2.9803 - accuracy: 0.2759 - val_loss: 3.0453 - val_accuracy: 0.3095\n",
            "Epoch 7/200\n",
            "4534/4534 [==============================] - 163s 36ms/step - loss: 2.9497 - accuracy: 0.2920 - val_loss: 2.9618 - val_accuracy: 0.3095\n",
            "Epoch 8/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.9587 - accuracy: 0.2903 - val_loss: 3.0701 - val_accuracy: 0.3095\n",
            "Epoch 9/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.9483 - accuracy: 0.2938 - val_loss: 3.0301 - val_accuracy: 0.3095\n",
            "Epoch 10/200\n",
            "4534/4534 [==============================] - 161s 35ms/step - loss: 3.0076 - accuracy: 0.2984 - val_loss: 2.9950 - val_accuracy: 0.3095\n",
            "\n",
            "Epoch 00010: loss improved from inf to 3.00761, saving model to /content/drive/My Drive/checkpoints_attention_mozbet/weights-010-3.0076.hdf5\n",
            "Epoch 11/200\n",
            "4534/4534 [==============================] - 162s 36ms/step - loss: 2.9301 - accuracy: 0.2975 - val_loss: 3.0401 - val_accuracy: 0.3095\n",
            "Epoch 12/200\n",
            "4534/4534 [==============================] - 163s 36ms/step - loss: 2.9255 - accuracy: 0.2973 - val_loss: 3.0329 - val_accuracy: 0.3095\n",
            "Epoch 13/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.9239 - accuracy: 0.2995 - val_loss: 3.0670 - val_accuracy: 0.3095\n",
            "Epoch 14/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.9287 - accuracy: 0.2991 - val_loss: 3.0165 - val_accuracy: 0.3095\n",
            "Epoch 15/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.9135 - accuracy: 0.2986 - val_loss: 2.9924 - val_accuracy: 0.3095\n",
            "Epoch 16/200\n",
            "4534/4534 [==============================] - 161s 35ms/step - loss: 2.9164 - accuracy: 0.3017 - val_loss: 2.9822 - val_accuracy: 0.3095\n",
            "Epoch 17/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.9115 - accuracy: 0.2995 - val_loss: 3.0122 - val_accuracy: 0.3095\n",
            "Epoch 18/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.9232 - accuracy: 0.2984 - val_loss: 2.9680 - val_accuracy: 0.3095\n",
            "Epoch 19/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.9033 - accuracy: 0.2982 - val_loss: 2.9837 - val_accuracy: 0.3095\n",
            "Epoch 20/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.9019 - accuracy: 0.2986 - val_loss: 3.0016 - val_accuracy: 0.3095\n",
            "\n",
            "Epoch 00020: loss improved from 3.00761 to 2.90192, saving model to /content/drive/My Drive/checkpoints_attention_mozbet/weights-020-2.9019.hdf5\n",
            "Epoch 21/200\n",
            "4534/4534 [==============================] - 161s 35ms/step - loss: 2.9061 - accuracy: 0.3017 - val_loss: 2.9688 - val_accuracy: 0.3095\n",
            "Epoch 22/200\n",
            "4534/4534 [==============================] - 163s 36ms/step - loss: 2.9130 - accuracy: 0.3006 - val_loss: 3.0086 - val_accuracy: 0.3095\n",
            "Epoch 23/200\n",
            "4534/4534 [==============================] - 163s 36ms/step - loss: 2.8929 - accuracy: 0.3011 - val_loss: 2.9875 - val_accuracy: 0.3095\n",
            "Epoch 24/200\n",
            "4534/4534 [==============================] - 165s 36ms/step - loss: 2.8944 - accuracy: 0.2986 - val_loss: 3.0416 - val_accuracy: 0.3095\n",
            "Epoch 25/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 2.9270 - accuracy: 0.2975 - val_loss: 2.9737 - val_accuracy: 0.3095\n",
            "Epoch 26/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 2.8886 - accuracy: 0.3017 - val_loss: 2.9941 - val_accuracy: 0.3095\n",
            "Epoch 27/200\n",
            "4534/4534 [==============================] - 163s 36ms/step - loss: 2.8844 - accuracy: 0.2995 - val_loss: 2.9971 - val_accuracy: 0.3095\n",
            "Epoch 28/200\n",
            "4534/4534 [==============================] - 162s 36ms/step - loss: 2.8799 - accuracy: 0.3008 - val_loss: 3.0022 - val_accuracy: 0.3095\n",
            "Epoch 29/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 2.8847 - accuracy: 0.3002 - val_loss: 2.9807 - val_accuracy: 0.3095\n",
            "Epoch 30/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.8701 - accuracy: 0.3008 - val_loss: 2.9882 - val_accuracy: 0.3095\n",
            "\n",
            "Epoch 00030: loss improved from 2.90192 to 2.87011, saving model to /content/drive/My Drive/checkpoints_attention_mozbet/weights-030-2.8701.hdf5\n",
            "Epoch 31/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8669 - accuracy: 0.3017 - val_loss: 3.0959 - val_accuracy: 0.2963\n",
            "Epoch 32/200\n",
            "4534/4534 [==============================] - 165s 36ms/step - loss: 2.8607 - accuracy: 0.3006 - val_loss: 2.9702 - val_accuracy: 0.3095\n",
            "Epoch 33/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.8580 - accuracy: 0.2997 - val_loss: 3.0363 - val_accuracy: 0.3095\n",
            "Epoch 34/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.8512 - accuracy: 0.3024 - val_loss: 2.9605 - val_accuracy: 0.3095\n",
            "Epoch 35/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.8500 - accuracy: 0.3000 - val_loss: 2.9756 - val_accuracy: 0.3095\n",
            "Epoch 36/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.9434 - accuracy: 0.2975 - val_loss: 3.0163 - val_accuracy: 0.3095\n",
            "Epoch 37/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8351 - accuracy: 0.2991 - val_loss: 3.0039 - val_accuracy: 0.3095\n",
            "Epoch 38/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8383 - accuracy: 0.3011 - val_loss: 2.9770 - val_accuracy: 0.3095\n",
            "Epoch 39/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8395 - accuracy: 0.3006 - val_loss: 3.0843 - val_accuracy: 0.3069\n",
            "Epoch 40/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 3.8821 - accuracy: 0.2726 - val_loss: 3.0013 - val_accuracy: 0.3095\n",
            "\n",
            "Epoch 00040: loss did not improve from 2.87011\n",
            "Epoch 41/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.9219 - accuracy: 0.3017 - val_loss: 2.9778 - val_accuracy: 0.3095\n",
            "Epoch 42/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.9145 - accuracy: 0.3017 - val_loss: 3.0143 - val_accuracy: 0.3095\n",
            "Epoch 43/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8924 - accuracy: 0.3017 - val_loss: 2.9658 - val_accuracy: 0.3095\n",
            "Epoch 44/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8910 - accuracy: 0.3017 - val_loss: 2.9745 - val_accuracy: 0.3095\n",
            "Epoch 45/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8887 - accuracy: 0.3017 - val_loss: 2.9865 - val_accuracy: 0.3095\n",
            "Epoch 46/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8919 - accuracy: 0.3017 - val_loss: 2.9686 - val_accuracy: 0.3095\n",
            "Epoch 47/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 3.7751 - accuracy: 0.2989 - val_loss: 2.9790 - val_accuracy: 0.3095\n",
            "Epoch 48/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8961 - accuracy: 0.3017 - val_loss: 2.9643 - val_accuracy: 0.3095\n",
            "Epoch 49/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.9785 - accuracy: 0.3017 - val_loss: 2.9852 - val_accuracy: 0.3095\n",
            "Epoch 50/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.8822 - accuracy: 0.3017 - val_loss: 3.0063 - val_accuracy: 0.3095\n",
            "\n",
            "Epoch 00050: loss did not improve from 2.87011\n",
            "Epoch 51/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.7614 - accuracy: 0.3077 - val_loss: 2.7635 - val_accuracy: 0.3166\n",
            "Epoch 52/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.6894 - accuracy: 0.3288 - val_loss: 2.6956 - val_accuracy: 0.3862\n",
            "Epoch 53/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.4952 - accuracy: 0.4248 - val_loss: 2.3939 - val_accuracy: 0.4815\n",
            "Epoch 54/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.3766 - accuracy: 0.4404 - val_loss: 2.6423 - val_accuracy: 0.4797\n",
            "Epoch 55/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.4951 - accuracy: 0.4074 - val_loss: 3.3222 - val_accuracy: 0.2725\n",
            "Epoch 56/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.5284 - accuracy: 0.4007 - val_loss: 2.9032 - val_accuracy: 0.3369\n",
            "Epoch 57/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.4188 - accuracy: 0.4455 - val_loss: 4.3193 - val_accuracy: 0.1720\n",
            "Epoch 58/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.3385 - accuracy: 0.4367 - val_loss: 2.1675 - val_accuracy: 0.4824\n",
            "Epoch 59/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.2685 - accuracy: 0.4413 - val_loss: 2.1645 - val_accuracy: 0.4868\n",
            "Epoch 60/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.2029 - accuracy: 0.4543 - val_loss: 2.1959 - val_accuracy: 0.4859\n",
            "\n",
            "Epoch 00060: loss improved from 2.87011 to 2.20287, saving model to /content/drive/My Drive/checkpoints_attention_mozbet/weights-060-2.2029.hdf5\n",
            "Epoch 61/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.3399 - accuracy: 0.4215 - val_loss: 2.2832 - val_accuracy: 0.4868\n",
            "Epoch 62/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.1655 - accuracy: 0.4559 - val_loss: 2.9948 - val_accuracy: 0.3104\n",
            "Epoch 63/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.1722 - accuracy: 0.4495 - val_loss: 2.1960 - val_accuracy: 0.4859\n",
            "Epoch 64/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.1218 - accuracy: 0.4581 - val_loss: 2.2285 - val_accuracy: 0.4859\n",
            "Epoch 65/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.1184 - accuracy: 0.4601 - val_loss: 2.2202 - val_accuracy: 0.4859\n",
            "Epoch 66/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.0917 - accuracy: 0.4643 - val_loss: 2.1500 - val_accuracy: 0.4859\n",
            "Epoch 67/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.0952 - accuracy: 0.4618 - val_loss: 2.1892 - val_accuracy: 0.4885\n",
            "Epoch 68/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.1033 - accuracy: 0.4629 - val_loss: 2.2190 - val_accuracy: 0.4859\n",
            "Epoch 69/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0780 - accuracy: 0.4627 - val_loss: 2.4722 - val_accuracy: 0.4550\n",
            "Epoch 70/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.0883 - accuracy: 0.4610 - val_loss: 2.1847 - val_accuracy: 0.4982\n",
            "\n",
            "Epoch 00070: loss improved from 2.20287 to 2.08829, saving model to /content/drive/My Drive/checkpoints_attention_mozbet/weights-070-2.0883.hdf5\n",
            "Epoch 71/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.0940 - accuracy: 0.4652 - val_loss: 2.2000 - val_accuracy: 0.4859\n",
            "Epoch 72/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.0675 - accuracy: 0.4645 - val_loss: 2.1914 - val_accuracy: 0.4859\n",
            "Epoch 73/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.1095 - accuracy: 0.4592 - val_loss: 2.1894 - val_accuracy: 0.4885\n",
            "Epoch 74/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.0821 - accuracy: 0.4623 - val_loss: 2.3964 - val_accuracy: 0.4868\n",
            "Epoch 75/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0696 - accuracy: 0.4649 - val_loss: 2.2045 - val_accuracy: 0.4885\n",
            "Epoch 76/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0868 - accuracy: 0.4607 - val_loss: 3.4895 - val_accuracy: 0.3422\n",
            "Epoch 77/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.1315 - accuracy: 0.4612 - val_loss: 2.2302 - val_accuracy: 0.4859\n",
            "Epoch 78/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0588 - accuracy: 0.4621 - val_loss: 2.3730 - val_accuracy: 0.4806\n",
            "Epoch 79/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0526 - accuracy: 0.4658 - val_loss: 2.2020 - val_accuracy: 0.4859\n",
            "Epoch 80/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.0559 - accuracy: 0.4645 - val_loss: 2.2266 - val_accuracy: 0.4859\n",
            "\n",
            "Epoch 00080: loss improved from 2.08829 to 2.05588, saving model to /content/drive/My Drive/checkpoints_attention_mozbet/weights-080-2.0559.hdf5\n",
            "Epoch 81/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.0989 - accuracy: 0.4605 - val_loss: 2.2038 - val_accuracy: 0.4894\n",
            "Epoch 82/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0510 - accuracy: 0.4632 - val_loss: 2.2820 - val_accuracy: 0.4868\n",
            "Epoch 83/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0707 - accuracy: 0.4625 - val_loss: 2.3230 - val_accuracy: 0.4841\n",
            "Epoch 84/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.0535 - accuracy: 0.4638 - val_loss: 2.2999 - val_accuracy: 0.4824\n",
            "Epoch 85/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.0570 - accuracy: 0.4627 - val_loss: 2.2344 - val_accuracy: 0.4815\n",
            "Epoch 86/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0588 - accuracy: 0.4592 - val_loss: 2.1788 - val_accuracy: 0.4859\n",
            "Epoch 87/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0375 - accuracy: 0.4663 - val_loss: 2.1684 - val_accuracy: 0.4859\n",
            "Epoch 88/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0804 - accuracy: 0.4601 - val_loss: 2.2049 - val_accuracy: 0.4859\n",
            "Epoch 89/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0488 - accuracy: 0.4652 - val_loss: 2.1620 - val_accuracy: 0.4859\n",
            "Epoch 90/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0380 - accuracy: 0.4660 - val_loss: 2.1828 - val_accuracy: 0.4859\n",
            "\n",
            "Epoch 00090: loss improved from 2.05588 to 2.03805, saving model to /content/drive/My Drive/checkpoints_attention_mozbet/weights-090-2.0380.hdf5\n",
            "Epoch 91/200\n",
            "4534/4534 [==============================] - 168s 37ms/step - loss: 2.0251 - accuracy: 0.4663 - val_loss: 2.2702 - val_accuracy: 0.4894\n",
            "Epoch 92/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0412 - accuracy: 0.4601 - val_loss: 2.1683 - val_accuracy: 0.4850\n",
            "Epoch 93/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0290 - accuracy: 0.4665 - val_loss: 2.2335 - val_accuracy: 0.4850\n",
            "Epoch 94/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0217 - accuracy: 0.4643 - val_loss: 2.1882 - val_accuracy: 0.4859\n",
            "Epoch 95/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0193 - accuracy: 0.4636 - val_loss: 2.1939 - val_accuracy: 0.4832\n",
            "Epoch 96/200\n",
            "4534/4534 [==============================] - 167s 37ms/step - loss: 2.0356 - accuracy: 0.4621 - val_loss: 2.2342 - val_accuracy: 0.4815\n",
            "Epoch 97/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.0365 - accuracy: 0.4596 - val_loss: 2.2706 - val_accuracy: 0.4859\n",
            "Epoch 98/200\n",
            "4534/4534 [==============================] - 166s 37ms/step - loss: 2.0210 - accuracy: 0.4636 - val_loss: 2.1945 - val_accuracy: 0.4877\n",
            "Epoch 99/200\n",
            "4534/4534 [==============================] - 163s 36ms/step - loss: 2.0080 - accuracy: 0.4645 - val_loss: 2.1996 - val_accuracy: 0.4859\n",
            "Epoch 100/200\n",
            "4534/4534 [==============================] - 161s 35ms/step - loss: 2.0049 - accuracy: 0.4667 - val_loss: 2.3345 - val_accuracy: 0.4824\n",
            "\n",
            "Epoch 00100: loss improved from 2.03805 to 2.00494, saving model to /content/drive/My Drive/checkpoints_attention_mozbet/weights-100-2.0049.hdf5\n",
            "Epoch 101/200\n",
            "4534/4534 [==============================] - 162s 36ms/step - loss: 2.0523 - accuracy: 0.4656 - val_loss: 2.2976 - val_accuracy: 0.4859\n",
            "Epoch 102/200\n",
            "4534/4534 [==============================] - 161s 36ms/step - loss: 2.0133 - accuracy: 0.4669 - val_loss: 2.3669 - val_accuracy: 0.4859\n",
            "Epoch 103/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.0126 - accuracy: 0.4636 - val_loss: 2.3140 - val_accuracy: 0.4850\n",
            "Epoch 104/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.0856 - accuracy: 0.4504 - val_loss: 2.5736 - val_accuracy: 0.4859\n",
            "Epoch 105/200\n",
            "4534/4534 [==============================] - 161s 35ms/step - loss: 2.0410 - accuracy: 0.4632 - val_loss: 2.1730 - val_accuracy: 0.4815\n",
            "Epoch 106/200\n",
            "4534/4534 [==============================] - 161s 35ms/step - loss: 2.0143 - accuracy: 0.4649 - val_loss: 2.1541 - val_accuracy: 0.4815\n",
            "Epoch 107/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.0023 - accuracy: 0.4665 - val_loss: 2.3548 - val_accuracy: 0.4859\n",
            "Epoch 108/200\n",
            "4534/4534 [==============================] - 160s 35ms/step - loss: 2.0022 - accuracy: 0.4658 - val_loss: 2.3303 - val_accuracy: 0.4859\n",
            "Epoch 109/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 1.9957 - accuracy: 0.4658 - val_loss: 2.2199 - val_accuracy: 0.4859\n",
            "Epoch 110/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 2.0539 - accuracy: 0.4632 - val_loss: 2.1392 - val_accuracy: 0.4859\n",
            "\n",
            "Epoch 00110: loss did not improve from 2.00494\n",
            "Epoch 111/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 1.9950 - accuracy: 0.4649 - val_loss: 2.7307 - val_accuracy: 0.4824\n",
            "Epoch 112/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 2.0159 - accuracy: 0.4636 - val_loss: 2.2040 - val_accuracy: 0.4850\n",
            "Epoch 113/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 2.0086 - accuracy: 0.4616 - val_loss: 2.2666 - val_accuracy: 0.4859\n",
            "Epoch 114/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 2.0157 - accuracy: 0.4680 - val_loss: 2.1863 - val_accuracy: 0.4859\n",
            "Epoch 115/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 1.9916 - accuracy: 0.4663 - val_loss: 2.2680 - val_accuracy: 0.4894\n",
            "Epoch 116/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 2.0194 - accuracy: 0.4636 - val_loss: 2.1590 - val_accuracy: 0.4859\n",
            "Epoch 117/200\n",
            "4534/4534 [==============================] - 158s 35ms/step - loss: 1.9853 - accuracy: 0.4674 - val_loss: 2.2574 - val_accuracy: 0.4859\n",
            "Epoch 118/200\n",
            "4534/4534 [==============================] - 158s 35ms/step - loss: 1.9966 - accuracy: 0.4656 - val_loss: 2.2185 - val_accuracy: 0.4850\n",
            "Epoch 119/200\n",
            "4534/4534 [==============================] - 158s 35ms/step - loss: 1.9754 - accuracy: 0.4674 - val_loss: 2.2457 - val_accuracy: 0.4859\n",
            "Epoch 120/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 1.9879 - accuracy: 0.4656 - val_loss: 2.1545 - val_accuracy: 0.4859\n",
            "\n",
            "Epoch 00120: loss improved from 2.00494 to 1.98791, saving model to /content/drive/My Drive/checkpoints_attention_mozbet/weights-120-1.9879.hdf5\n",
            "Epoch 121/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 1.9849 - accuracy: 0.4674 - val_loss: 2.4405 - val_accuracy: 0.4859\n",
            "Epoch 122/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 1.9832 - accuracy: 0.4654 - val_loss: 2.2678 - val_accuracy: 0.4859\n",
            "Epoch 123/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 1.9835 - accuracy: 0.4671 - val_loss: 2.2064 - val_accuracy: 0.4850\n",
            "Epoch 124/200\n",
            "4534/4534 [==============================] - 158s 35ms/step - loss: 1.9882 - accuracy: 0.4649 - val_loss: 2.2094 - val_accuracy: 0.4859\n",
            "Epoch 125/200\n",
            "4534/4534 [==============================] - 159s 35ms/step - loss: 2.0294 - accuracy: 0.4643 - val_loss: 2.2638 - val_accuracy: 0.4859\n",
            "Epoch 126/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 1.9820 - accuracy: 0.4649 - val_loss: 2.2223 - val_accuracy: 0.4850\n",
            "Epoch 127/200\n",
            "4534/4534 [==============================] - 165s 36ms/step - loss: 1.9739 - accuracy: 0.4656 - val_loss: 2.1930 - val_accuracy: 0.4859\n",
            "Epoch 128/200\n",
            "4534/4534 [==============================] - 165s 36ms/step - loss: 1.9785 - accuracy: 0.4665 - val_loss: 2.1929 - val_accuracy: 0.4859\n",
            "Epoch 129/200\n",
            "4534/4534 [==============================] - 165s 36ms/step - loss: 1.9896 - accuracy: 0.4667 - val_loss: 2.1827 - val_accuracy: 0.4859\n",
            "Epoch 130/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 1.9887 - accuracy: 0.4667 - val_loss: 2.1928 - val_accuracy: 0.4850\n",
            "\n",
            "Epoch 00130: loss did not improve from 1.98791\n",
            "Epoch 131/200\n",
            "4534/4534 [==============================] - 165s 36ms/step - loss: 1.9850 - accuracy: 0.4647 - val_loss: 2.1723 - val_accuracy: 0.4859\n",
            "Epoch 132/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 1.9916 - accuracy: 0.4643 - val_loss: 2.1802 - val_accuracy: 0.4832\n",
            "Epoch 133/200\n",
            "4534/4534 [==============================] - 165s 36ms/step - loss: 1.9740 - accuracy: 0.4654 - val_loss: 2.1820 - val_accuracy: 0.4859\n",
            "Epoch 134/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 1.9700 - accuracy: 0.4669 - val_loss: 2.2399 - val_accuracy: 0.4850\n",
            "Epoch 135/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 1.9851 - accuracy: 0.4663 - val_loss: 2.2317 - val_accuracy: 0.4859\n",
            "Epoch 136/200\n",
            "4534/4534 [==============================] - 164s 36ms/step - loss: 1.9730 - accuracy: 0.4671 - val_loss: 2.2832 - val_accuracy: 0.4859\n",
            "Epoch 137/200\n",
            " 768/4534 [====>.........................] - ETA: 2:14 - loss: 1.8835 - accuracy: 0.4818"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2ZZJ6ZqYVaw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7iNhd6LY-U0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FtfvDh9Ak7V2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#len(glob.glob(train_path + '**/*nokey.mid', recursive=True))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}